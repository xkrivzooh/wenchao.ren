<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on 被遗忘的博客</title>
    <link>https://wenchao.ren/tags/spark/</link>
    <description>Recent content in spark on 被遗忘的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 23 Jan 2019 00:27:31 +0000</lastBuildDate><atom:link href="https://wenchao.ren/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark 通用数据访问</title>
      <link>https://wenchao.ren/posts/spark-%E9%80%9A%E7%94%A8%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/</link>
      <pubDate>Wed, 23 Jan 2019 00:27:31 +0000</pubDate>
      
      <guid>https://wenchao.ren/posts/spark-%E9%80%9A%E7%94%A8%E6%95%B0%E6%8D%AE%E8%AE%BF%E9%97%AE/</guid>
      <description>##Data abstractions RDD is the core abstraction in Apache Spark. It is an immutable, fault-tolerant distributed collection of statically typed objects that are usually stored in-memory. DataFrame abstraction is built on top of RDD and it adds “named” columns. Moreover, the Catalyst optimizer, under the hood, compiles the operations and generates JVM bytecode for efficient execution.
 However, the named columns approach gives rise to a new problem. Static type information is no longer available to the compiler, and hence we lose the advantage of compile-time type safety.</description>
    </item>
    
    <item>
      <title>理解Compressed Sparse Column Format (CSC)</title>
      <link>https://wenchao.ren/posts/%E7%90%86%E8%A7%A3compressed-sparse-column-format-csc/</link>
      <pubDate>Wed, 23 Jan 2019 00:25:21 +0000</pubDate>
      
      <guid>https://wenchao.ren/posts/%E7%90%86%E8%A7%A3compressed-sparse-column-format-csc/</guid>
      <description>最近在看《Spark for Data Science》这本书，阅读到《Machine Learning》这一节的时候被稀疏矩阵的存储格式CSC给弄的晕头转向的。所以专门写一篇文章记录一下我对这种格式的理解。
##目的 Compressed Sparse Column Format (CSC)的目的是为了压缩矩阵，减少矩阵存储所占用的空间。这很好理解，手法无法就是通过增加一些&amp;quot;元信息&amp;quot;来描述矩阵中的非零元素存储的位置(基于列)，然后结合非零元素的值来表示矩阵。这样在一些场景下可以减少矩阵存储的空间。
##Spark API
在Spark中我们一般创建这样的稀疏矩阵的API为：
package org.apache.spark.ml.linalg /** * Creates a column-major sparse matrix in Compressed Sparse Column (CSC) format. * * @param numRows number of rows * @param numCols number of columns * @param colPtrs the index corresponding to the start of a new column * @param rowIndices the row index of the entry * @param values non-zero matrix entries in column major */ @Since(&amp;quot;2.</description>
    </item>
    
  </channel>
</rss>
